{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "OCR.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "tqV3oHrg8mY-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import print_function, division\n",
        "import os\n",
        "import torch\n",
        "from torch.optim.optimizer import Optimizer\n",
        "from skimage import io, transform\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, utils\n",
        "from skimage import io\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from skimage.color import rgb2gray\n",
        "\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "import PIL\n",
        "from PIL import Image\n",
        "\n",
        "from google.colab import output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qZPVvFlrIHMt",
        "colab_type": "code",
        "outputId": "6222bf28-ac6e-40c8-d71d-0d30dbee225a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "%cd /content/\n",
        "if(os.path.isdir('/content/Lithuanian_OCR') == False):\n",
        "  !git clone https://github.com/PauliusMilmantas/Lithuanian_OCR\n",
        "\n",
        "num_of_classes = 3"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "Cloning into 'Lithuanian_OCR'...\n",
            "remote: Enumerating objects: 145, done.\u001b[K\n",
            "remote: Counting objects: 100% (145/145), done.\u001b[K\n",
            "remote: Compressing objects: 100% (105/105), done.\u001b[K\n",
            "remote: Total 4130 (delta 37), reused 136 (delta 29), pack-reused 3985\u001b[K\n",
            "Receiving objects: 100% (4130/4130), 329.53 MiB | 38.60 MiB/s, done.\n",
            "Resolving deltas: 100% (655/655), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4dizldPQRNUj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ORCDataset(Dataset):\n",
        "  def __init__(self, root):\n",
        "    self.root = root\n",
        "\n",
        "  def __len__(self):\n",
        "    lt = 0\n",
        "    classes = os.listdir(self.root)\n",
        "    for cl in classes:\n",
        "      lt += len(os.listdir(self.root + '/' + cl))\n",
        "\n",
        "    return lt\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    if torch.is_tensor(idx):\n",
        "     idx = idx.tolist()\n",
        "\n",
        "    if(idx <= len(self)):\n",
        "      found_file = \"\"\n",
        "      found_type = \"\"\n",
        "\n",
        "      fldrs = os.listdir(self.root)\n",
        "      for fld in fldrs:\n",
        "        fls = os.listdir(self.root + '/' + fld + '/')\n",
        "        for fl in fls:\n",
        "          if(fl == str(idx) + \".jpg\"):\n",
        "            found_file = self.root + '/' + fld + '/' + fl         \n",
        "            found_type = fld\n",
        "\n",
        "      try:\n",
        "        img = io.imread(found_file)\n",
        "        img = rgb2gray(img)\n",
        "\n",
        "        return {'image': img, 'class_name': found_type}\n",
        "      except:\n",
        "        if(found_file != \"\"):\n",
        "          print(\"Bad file: \" + found_file)\n",
        "        else:\n",
        "          print(\"File not found, idx = \" + str(idx))\n",
        "    else:\n",
        "      print()\n",
        "      raise Exception(\"Dataset index out of boundaries\")\n",
        "\n",
        "train_dataset = ORCDataset('/content/Lithuanian_OCR/Data/batch-2/training')\n",
        "val_dataset = ORCDataset('/content/Lithuanian_OCR/Data/batch-2/val')\n",
        "test_dataset = ORCDataset('/content/Lithuanian_OCR/Data/batch-2/test')\n",
        "\n",
        "other_train_dataset = ORCDataset('/content/Lithuanian_OCR/Data/batch-1/training')\n",
        "other_val_dataset = ORCDataset('/content/Lithuanian_OCR/Data/batch-1/val')\n",
        "other_test_dataset = ORCDataset('/content/Lithuanian_OCR/Data/batch-1/test')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KR2HO96n8pXN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self, input_size, hidden1_size, hidden2_size, num_classes):\n",
        "        super(Net, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, hidden1_size)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(hidden1_size, hidden2_size)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.fc3 = nn.Linear(hidden2_size, num_classes)  \n",
        "    \n",
        "    def forward(self, x):\n",
        "        out = self.fc1(x)\n",
        "        out = self.relu1(out)\n",
        "        out = self.fc2(out)        \n",
        "        out = self.relu2(out)     \n",
        "        out = self.fc3(out)\n",
        "        return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HrA0syykfUCm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class custom_sgd_optimizer(Optimizer):\n",
        "    def __init__(self, params, lr, momentum=0, dampening=0,\n",
        "                 weight_decay=0, nesterov=False):\n",
        "\n",
        "        defaults = dict(lr=lr, momentum=momentum, dampening=dampening,\n",
        "                        weight_decay=weight_decay, nesterov=nesterov)\n",
        "        if nesterov and (momentum <= 0 or dampening != 0):\n",
        "            raise ValueError(\"Nesterov momentum requires a momentum and zero dampening\")\n",
        "        super(custom_sgd_optimizer, self).__init__(params, defaults)\n",
        "\n",
        "    def __setstate__(self, state):\n",
        "        super(custom_sgd_optimizer, self).__setstate__(state)\n",
        "        for group in self.param_groups:\n",
        "            group.setdefault('nesterov', False)\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def step(self, closure=None):\n",
        "        \"\"\"Performs a single optimization step.\n",
        "        Arguments:\n",
        "            closure (callable, optional): A closure that reevaluates the model\n",
        "                and returns the loss.\n",
        "        \"\"\"\n",
        "        loss = None\n",
        "        if closure is not None:\n",
        "            with torch.enable_grad():\n",
        "                loss = closure()\n",
        "\n",
        "        for group in self.param_groups:\n",
        "            weight_decay = group['weight_decay']\n",
        "            momentum = group['momentum']\n",
        "            dampening = group['dampening']\n",
        "            nesterov = group['nesterov']\n",
        "\n",
        "            for p in group['params']:\n",
        "                if p.grad is None:\n",
        "                    continue\n",
        "                d_p = p.grad\n",
        "                if weight_decay != 0:\n",
        "                    d_p = d_p.add(p, alpha=weight_decay)\n",
        "                if momentum != 0:\n",
        "                    param_state = self.state[p]\n",
        "                    if 'momentum_buffer' not in param_state:\n",
        "                        buf = param_state['momentum_buffer'] = torch.clone(d_p).detach()\n",
        "                    else:\n",
        "                        buf = param_state['momentum_buffer']\n",
        "                        buf.mul_(momentum).add_(d_p, alpha=1 - dampening)\n",
        "                    if nesterov:\n",
        "                        d_p = d_p.add(buf, alpha=momentum)\n",
        "                    else:\n",
        "                        d_p = buf\n",
        "\n",
        "                p.add_(d_p, alpha=-group['lr'])\n",
        "\n",
        "        return loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MwTzb7K0_OSi",
        "colab_type": "code",
        "outputId": "2a755858-3245-457a-9a3d-b5641dd0913a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "network = Net(4096, 1500, 300, num_of_classes)\n",
        "network.cuda()\n",
        "optimizer = torch.optim.SGD(network.parameters(), lr=0.0001, momentum=0.6)\n",
        "criterion = nn.MSELoss().cuda()\n",
        "\n",
        "print(network)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Net(\n",
            "  (fc1): Linear(in_features=4096, out_features=1500, bias=True)\n",
            "  (relu1): ReLU()\n",
            "  (fc2): Linear(in_features=1500, out_features=300, bias=True)\n",
            "  (relu2): ReLU()\n",
            "  (fc3): Linear(in_features=300, out_features=3, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dMTTpgG39U9y",
        "colab_type": "code",
        "outputId": "5b1346a9-2f44-46f0-9e03-ce5d68a29063",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "dev = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "network.to(dev)\n",
        "criterion.to(dev)\n",
        "dev"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FsOVe0KqWNts",
        "colab_type": "code",
        "outputId": "9457a019-6a32-4749-c5bc-94ac522aaa00",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('Using device:', device)\n",
        "print()\n",
        "\n",
        "#Additional Info when using cuda\n",
        "if device.type == 'cuda':\n",
        "    print(torch.cuda.get_device_name(0))\n",
        "    print('Memory Usage:')\n",
        "    print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
        "    print('Cached:   ', round(torch.cuda.memory_cached(0)/1024**3,1), 'GB')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using device: cuda\n",
            "\n",
            "Tesla P100-PCIE-16GB\n",
            "Memory Usage:\n",
            "Allocated: 0.0 GB\n",
            "Cached:    0.0 GB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KIOL9zLnKiEu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size = len(train_dataset),shuffle=True)\n",
        "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size = len(val_dataset), shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size = len(test_dataset), shuffle=True)\n",
        "\n",
        "other_train_loader = torch.utils.data.DataLoader(other_train_dataset, batch_size = len(other_train_dataset),shuffle=True)\n",
        "other_val_loader = torch.utils.data.DataLoader(other_val_dataset, batch_size = len(other_val_dataset), shuffle=True)\n",
        "other_test_loader = torch.utils.data.DataLoader(other_test_dataset, batch_size = len(other_test_dataset), shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SAi_TQWW-04_",
        "colab_type": "code",
        "outputId": "ddc90746-1a8d-475c-ce63-1766c9a580cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        }
      },
      "source": [
        "dataiter = iter(train_loader)\n",
        "itr = dataiter.next()\n",
        "\n",
        "label = itr['class_name']\n",
        "img = itr['image']\n",
        "print(\"Class name: {}\".format(label[0]))\n",
        "\n",
        "fig = plt.figure(figsize = (5,5)) \n",
        "ax = fig.add_subplot(111)\n",
        "ax.imshow(img[0])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Class name: P\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f73a2cc9e80>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 360x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LMbDr5k1BOPE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_losses = []\n",
        "train_counter = []\n",
        "test_losses = []\n",
        "test_counter = [i*len(train_loader.dataset) for i in range(10 + 1)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aCwc6dI0BfdU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir results"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WNsrIgqgbT15",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def name_to_int(data):\n",
        "\n",
        "  switcher = {\n",
        "      'A': 1,\n",
        "      'B': 2,\n",
        "      'C': 3,\n",
        "      'A_small': 1,\n",
        "      'P': 2,\n",
        "      'u': 3\n",
        "  }\n",
        "\n",
        "  new_data = []\n",
        "\n",
        "  for dt in data:\n",
        "    new_data.append(switcher.get(dt))\n",
        "\n",
        "  return new_data\n",
        "\n",
        "def get_max_from_tensor(data):\n",
        "  maxVal = data[0]\n",
        "  maxId = 0\n",
        "  for i in range(len(data)):\n",
        "    if(data[i] > maxVal):\n",
        "      maxVal = data[i]\n",
        "      maxId = i\n",
        "\n",
        "  return maxId + 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MT60UZQ5sQvj",
        "colab_type": "code",
        "outputId": "1e67a9d9-2a46-4d7f-d4d0-e22d2097c50a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "def train(train_loader, val_loader, epoch_amount, save_checkpoint = 10):\n",
        "  network.eval()\n",
        "  train_loss_hist = []\n",
        "  val_loss_hist = []\n",
        "\n",
        "  other_train_loss_hist = []\n",
        "\n",
        "  checkpoint = save_checkpoint\n",
        "  for epoch in range(epoch_amount):\n",
        "    num_images_train = 0\n",
        "    num_other_images_train = 0\n",
        "\n",
        "    # TRAINING DATASET\n",
        "    correct = 0\n",
        "    other_correct = 0\n",
        "    for data in train_loader:\n",
        "      images = data['image']\n",
        "      labels = torch.from_numpy(np.array(name_to_int(data['class_name'])))\n",
        "\n",
        "      lossSum = 0\n",
        "      for idx in range(len(images)):\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = network(images[idx].cuda().flatten().float())\n",
        "\n",
        "        maxIdx = get_max_from_tensor(outputs)\n",
        "        real_value = np.repeat(-10, num_of_classes)\n",
        "        real_value[labels[idx] - 1] = 10\n",
        "        loss = criterion(outputs.cuda(), torch.Tensor(real_value).cuda()) \n",
        "        \n",
        "        loss.backward()\n",
        "\n",
        "        lossSum += loss.item()\n",
        "        train_loss_hist.append(lossSum)\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "    # TRAINING FOR OTHER DATASET\n",
        "    for data in other_train_loader:\n",
        "      images = data['image']\n",
        "\n",
        "      lossSum = 0\n",
        "      for idx in range(len(images)):\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = network(images[idx].cuda().flatten().float())\n",
        "\n",
        "        real_value = np.repeat(-10, num_of_classes)\n",
        "        loss = criterion(outputs.cuda(), torch.Tensor(real_value).cuda()) \n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        lossSum += loss.item()\n",
        "        other_train_loss_hist.append(lossSum)\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "    # VALIDATION\n",
        "    for data in val_loader:\n",
        "      images = data['image']\n",
        "      labels = torch.from_numpy(np.array(name_to_int(data['class_name'])))\n",
        "\n",
        "      num_images_train = len(images)\n",
        "\n",
        "      images.cuda()\n",
        "      labels.cuda()\n",
        "\n",
        "      lossSum = 0\n",
        "      for idx in range(len(images)):\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = network(images[idx].cuda().flatten().float())\n",
        "\n",
        "        if(labels[idx] == get_max_from_tensor(outputs)):\n",
        "          correct += 1\n",
        "\n",
        "        maxIdx = get_max_from_tensor(outputs)\n",
        "        real_value = np.repeat(-10, num_of_classes)\n",
        "        real_value[labels[idx] - 1] = 10\n",
        "        loss = criterion(outputs.cuda(), torch.Tensor(real_value).cuda()) \n",
        "\n",
        "        lossSum += loss.item()\n",
        "        val_loss_hist.append(lossSum)\n",
        "\n",
        "    print(\"Epoch: {} Training loss: {} Eval loss: {} Other DB loss: {} Correct: {}%\".format(epoch,train_loss_hist[len(train_loss_hist) - 1],val_loss_hist[len(val_loss_hist) - 1], other_train_loss_hist[len(other_train_loss_hist) - 1], correct*100/num_images_train))\n",
        "\n",
        "    if(checkpoint == 0):\n",
        "      torch.save(network.state_dict(), '/content/results/model.pth')\n",
        "      torch.save(optimizer.state_dict(), '/content/results/optimizer.pth')\n",
        "\n",
        "      checkpoint = save_checkpoint\n",
        "    else:\n",
        "      checkpoint -= 1\n",
        "\n",
        "train(train_loader, val_loader, 100, 5)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0 Training loss: 133.32186107034795 Eval loss: 2250.549775123596 Other DB loss: 90.50338265509345 Correct: 94.23076923076923%\n",
            "Epoch: 1 Training loss: 80.86398392636329 Eval loss: 2808.1729412078857 Other DB loss: 131.23813959932886 Correct: 90.38461538461539%\n",
            "Epoch: 2 Training loss: 131.33784662140533 Eval loss: 2275.071533679962 Other DB loss: 83.4024684263859 Correct: 94.23076923076923%\n",
            "Epoch: 3 Training loss: 75.89037290983833 Eval loss: 2580.926184654236 Other DB loss: 104.6186880460009 Correct: 88.46153846153847%\n",
            "Epoch: 4 Training loss: 152.01691896514967 Eval loss: 2436.654842853546 Other DB loss: 94.28518627234735 Correct: 90.38461538461539%\n",
            "Epoch: 5 Training loss: 89.9847984323278 Eval loss: 2314.238767147064 Other DB loss: 80.04830390866846 Correct: 90.38461538461539%\n",
            "Epoch: 6 Training loss: 85.64265008154325 Eval loss: 2286.7923216819763 Other DB loss: 94.32614778354764 Correct: 86.53846153846153%\n",
            "Epoch: 7 Training loss: 133.93548855697736 Eval loss: 2374.621413707733 Other DB loss: 91.90158817451447 Correct: 90.38461538461539%\n",
            "Epoch: 8 Training loss: 97.93985583772883 Eval loss: 2132.8125824928284 Other DB loss: 86.19165643490851 Correct: 92.3076923076923%\n",
            "Epoch: 9 Training loss: 72.37307650782168 Eval loss: 2063.062621116638 Other DB loss: 73.14156835898757 Correct: 88.46153846153847%\n",
            "Epoch: 10 Training loss: 67.12263427581638 Eval loss: 2429.8769912719727 Other DB loss: 87.56412196380552 Correct: 94.23076923076923%\n",
            "Epoch: 11 Training loss: 81.40458511700854 Eval loss: 2014.2592182159424 Other DB loss: 67.9808023996884 Correct: 94.23076923076923%\n",
            "Epoch: 12 Training loss: 58.66527687886264 Eval loss: 2021.5367856025696 Other DB loss: 63.015173866413534 Correct: 92.3076923076923%\n",
            "Epoch: 13 Training loss: 55.56194335850887 Eval loss: 2118.2413024902344 Other DB loss: 72.15117358774296 Correct: 86.53846153846153%\n",
            "Epoch: 14 Training loss: 74.95839063753374 Eval loss: 2424.5899047851562 Other DB loss: 81.10789207881317 Correct: 84.61538461538461%\n",
            "Epoch: 15 Training loss: 162.89662549784407 Eval loss: 2154.1181225776672 Other DB loss: 68.92365013324888 Correct: 94.23076923076923%\n",
            "Epoch: 16 Training loss: 71.52550635911757 Eval loss: 2254.5145721435547 Other DB loss: 75.55630044275313 Correct: 92.3076923076923%\n",
            "Epoch: 17 Training loss: 65.70182813005522 Eval loss: 2132.874059200287 Other DB loss: 66.97328754304908 Correct: 92.3076923076923%\n",
            "Epoch: 18 Training loss: 55.243932395474985 Eval loss: 1823.832738161087 Other DB loss: 58.26399170231889 Correct: 94.23076923076923%\n",
            "Epoch: 19 Training loss: 61.03558211401105 Eval loss: 2343.170943260193 Other DB loss: 82.41156755971315 Correct: 92.3076923076923%\n",
            "Epoch: 20 Training loss: 77.5003959556343 Eval loss: 2160.846405982971 Other DB loss: 70.58893889305182 Correct: 90.38461538461539%\n",
            "Epoch: 21 Training loss: 71.59087999793701 Eval loss: 2228.33331823349 Other DB loss: 82.04034063988365 Correct: 92.3076923076923%\n",
            "Epoch: 22 Training loss: 64.41472416347824 Eval loss: 2029.1284174919128 Other DB loss: 56.32648208353203 Correct: 92.3076923076923%\n",
            "Epoch: 23 Training loss: 58.671992858406156 Eval loss: 1926.1750602722168 Other DB loss: 56.96785413729958 Correct: 94.23076923076923%\n",
            "Epoch: 24 Training loss: 59.49902481841855 Eval loss: 1892.799369096756 Other DB loss: 59.26608807966113 Correct: 92.3076923076923%\n",
            "Epoch: 25 Training loss: 45.18412550678477 Eval loss: 1849.1020576953888 Other DB loss: 50.640885181957856 Correct: 92.3076923076923%\n",
            "Epoch: 26 Training loss: 43.90911792642146 Eval loss: 1870.977213859558 Other DB loss: 46.39932824429707 Correct: 92.3076923076923%\n",
            "Epoch: 27 Training loss: 45.14271310705226 Eval loss: 1862.9486532211304 Other DB loss: 46.7585290428251 Correct: 94.23076923076923%\n",
            "Epoch: 28 Training loss: 76.11897157944622 Eval loss: 1805.5540223121643 Other DB loss: 46.487878070023726 Correct: 94.23076923076923%\n",
            "Epoch: 29 Training loss: 53.13646368222544 Eval loss: 1932.168653011322 Other DB loss: 51.30761643772712 Correct: 86.53846153846153%\n",
            "Epoch: 30 Training loss: 46.051130435662344 Eval loss: 2538.244639635086 Other DB loss: 68.07186531811021 Correct: 86.53846153846153%\n",
            "Epoch: 31 Training loss: 149.11752066906774 Eval loss: 2218.822397708893 Other DB loss: 79.29464676656062 Correct: 86.53846153846153%\n",
            "Epoch: 32 Training loss: 60.07285505509935 Eval loss: 2269.59476685524 Other DB loss: 64.81573029066203 Correct: 92.3076923076923%\n",
            "Epoch: 33 Training loss: 135.32484189595561 Eval loss: 1864.6480221748352 Other DB loss: 50.04324951628223 Correct: 94.23076923076923%\n",
            "Epoch: 34 Training loss: 43.61307559139095 Eval loss: 1875.437604188919 Other DB loss: 44.5900393120246 Correct: 92.3076923076923%\n",
            "Epoch: 35 Training loss: 39.76647663640324 Eval loss: 2394.26766872406 Other DB loss: 53.58975927752908 Correct: 94.23076923076923%\n",
            "Epoch: 36 Training loss: 69.82559443160426 Eval loss: 1914.7744028568268 Other DB loss: 43.58364188083215 Correct: 92.3076923076923%\n",
            "Epoch: 37 Training loss: 45.73370722733671 Eval loss: 2107.4370839595795 Other DB loss: 45.49874372826889 Correct: 92.3076923076923%\n",
            "Epoch: 38 Training loss: 49.648457027971745 Eval loss: 2049.747275829315 Other DB loss: 42.59151877253316 Correct: 90.38461538461539%\n",
            "Epoch: 39 Training loss: 70.87639453972224 Eval loss: 1850.3231468200684 Other DB loss: 40.99648187472485 Correct: 92.3076923076923%\n",
            "Epoch: 40 Training loss: 39.68195581238251 Eval loss: 1836.5335657596588 Other DB loss: 37.472180248907534 Correct: 92.3076923076923%\n",
            "Epoch: 41 Training loss: 77.60607197904028 Eval loss: 1916.2254445552826 Other DB loss: 44.44071632332634 Correct: 92.3076923076923%\n",
            "Epoch: 42 Training loss: 42.35311134788208 Eval loss: 1862.6823761463165 Other DB loss: 37.498365069623105 Correct: 94.23076923076923%\n",
            "Epoch: 43 Training loss: 40.756852051243186 Eval loss: 1799.4631524085999 Other DB loss: 35.442367149255006 Correct: 94.23076923076923%\n",
            "Epoch: 44 Training loss: 34.23977381869918 Eval loss: 1862.6797354221344 Other DB loss: 37.05256304232171 Correct: 92.3076923076923%\n",
            "Epoch: 45 Training loss: 37.3103936042171 Eval loss: 1815.449731349945 Other DB loss: 37.0091805132397 Correct: 92.3076923076923%\n",
            "Epoch: 46 Training loss: 28.466327459842432 Eval loss: 2151.6244382858276 Other DB loss: 43.03370781771082 Correct: 92.3076923076923%\n",
            "Epoch: 47 Training loss: 116.41705734329298 Eval loss: 1696.5429456233978 Other DB loss: 37.71569974592421 Correct: 92.3076923076923%\n",
            "Epoch: 48 Training loss: 40.02712587849237 Eval loss: 1655.8895344734192 Other DB loss: 35.31772178976098 Correct: 94.23076923076923%\n",
            "Epoch: 49 Training loss: 31.42466355243232 Eval loss: 1877.8335583209991 Other DB loss: 37.02436232089531 Correct: 92.3076923076923%\n",
            "Epoch: 50 Training loss: 33.69299250131007 Eval loss: 1836.0878829956055 Other DB loss: 33.5072673320974 Correct: 94.23076923076923%\n",
            "Epoch: 51 Training loss: 33.422899807221256 Eval loss: 1995.3051619529724 Other DB loss: 37.067483398961485 Correct: 92.3076923076923%\n",
            "Epoch: 52 Training loss: 56.733366253378335 Eval loss: 1985.2594220638275 Other DB loss: 56.35900482389843 Correct: 88.46153846153847%\n",
            "Epoch: 53 Training loss: 43.987854070204776 Eval loss: 1655.357277393341 Other DB loss: 33.57547607639572 Correct: 92.3076923076923%\n",
            "Epoch: 54 Training loss: 26.506410620640963 Eval loss: 1756.597143650055 Other DB loss: 33.268822858750354 Correct: 92.3076923076923%\n",
            "Epoch: 55 Training loss: 29.331619373639114 Eval loss: 1603.3186694383621 Other DB loss: 28.55447228392586 Correct: 92.3076923076923%\n",
            "Epoch: 56 Training loss: 45.3047051547328 Eval loss: 1840.8991482257843 Other DB loss: 34.64101877971552 Correct: 92.3076923076923%\n",
            "Epoch: 57 Training loss: 35.737994381110184 Eval loss: 1846.6791779994965 Other DB loss: 35.06487836904125 Correct: 92.3076923076923%\n",
            "Epoch: 58 Training loss: 40.07631130506343 Eval loss: 1709.8879979848862 Other DB loss: 28.227708258433267 Correct: 94.23076923076923%\n",
            "Epoch: 59 Training loss: 33.29392659725272 Eval loss: 1839.324171423912 Other DB loss: 32.36406636110041 Correct: 90.38461538461539%\n",
            "Epoch: 60 Training loss: 36.43485688336659 Eval loss: 1619.4582424163818 Other DB loss: 28.167195548463496 Correct: 92.3076923076923%\n",
            "Epoch: 61 Training loss: 23.389503597514704 Eval loss: 2110.3733756542206 Other DB loss: 35.44154152710689 Correct: 94.23076923076923%\n",
            "Epoch: 62 Training loss: 35.25961381022353 Eval loss: 1643.0754364728928 Other DB loss: 25.710829282084887 Correct: 92.3076923076923%\n",
            "Epoch: 63 Training loss: 34.903266400506254 Eval loss: 1653.0779210329056 Other DB loss: 27.160109153366648 Correct: 96.15384615384616%\n",
            "Epoch: 64 Training loss: 26.58441821447923 Eval loss: 1641.247211933136 Other DB loss: 21.86234306334518 Correct: 94.23076923076923%\n",
            "Epoch: 65 Training loss: 27.375736403177143 Eval loss: 1566.624709367752 Other DB loss: 26.983003476394515 Correct: 94.23076923076923%\n",
            "Epoch: 66 Training loss: 23.526405574171804 Eval loss: 1790.329253435135 Other DB loss: 29.458749848243315 Correct: 94.23076923076923%\n",
            "Epoch: 67 Training loss: 30.18682907067705 Eval loss: 2062.7291291952133 Other DB loss: 39.56756077631144 Correct: 92.3076923076923%\n",
            "Epoch: 68 Training loss: 39.106201336486265 Eval loss: 1769.9195952415466 Other DB loss: 28.493386963615194 Correct: 90.38461538461539%\n",
            "Epoch: 69 Training loss: 26.03992816293612 Eval loss: 1716.9516288042068 Other DB loss: 23.41213187284302 Correct: 94.23076923076923%\n",
            "Epoch: 70 Training loss: 29.34963692515157 Eval loss: 1743.2914754152298 Other DB loss: 27.065173126000445 Correct: 92.3076923076923%\n",
            "Epoch: 71 Training loss: 23.002149418578483 Eval loss: 1735.260293006897 Other DB loss: 24.76804316532798 Correct: 94.23076923076923%\n",
            "Epoch: 72 Training loss: 30.74127157847397 Eval loss: 1873.5001003742218 Other DB loss: 27.700638650741894 Correct: 94.23076923076923%\n",
            "Epoch: 73 Training loss: 41.206087744852994 Eval loss: 2093.7235420942307 Other DB loss: 41.96792032587109 Correct: 92.3076923076923%\n",
            "Epoch: 74 Training loss: 45.27556808158988 Eval loss: 1596.877895116806 Other DB loss: 23.506619651714573 Correct: 92.3076923076923%\n",
            "Epoch: 75 Training loss: 22.033381009707227 Eval loss: 1617.6325097084045 Other DB loss: 22.146449794061482 Correct: 96.15384615384616%\n",
            "Epoch: 76 Training loss: 22.775194961577654 Eval loss: 1631.5443167686462 Other DB loss: 22.588310488092247 Correct: 92.3076923076923%\n",
            "Epoch: 77 Training loss: 20.109070409438573 Eval loss: 1691.9275990724564 Other DB loss: 21.135554895212408 Correct: 92.3076923076923%\n",
            "Epoch: 78 Training loss: 23.331856085453182 Eval loss: 1642.177795290947 Other DB loss: 21.302655923514976 Correct: 92.3076923076923%\n",
            "Epoch: 79 Training loss: 18.875279276631773 Eval loss: 1586.8227190971375 Other DB loss: 19.866160683333874 Correct: 94.23076923076923%\n",
            "Epoch: 80 Training loss: 16.26568514300743 Eval loss: 1627.8950234651566 Other DB loss: 20.44474741059821 Correct: 92.3076923076923%\n",
            "Epoch: 81 Training loss: 21.173090596916154 Eval loss: 1952.6287519931793 Other DB loss: 25.565913214813918 Correct: 90.38461538461539%\n",
            "Epoch: 82 Training loss: 69.69029022392351 Eval loss: 1665.5714906454086 Other DB loss: 22.136224828020204 Correct: 92.3076923076923%\n",
            "Epoch: 83 Training loss: 25.792950560571626 Eval loss: 1650.9523384571075 Other DB loss: 18.08639417192171 Correct: 94.23076923076923%\n",
            "Epoch: 84 Training loss: 20.578238221874926 Eval loss: 1692.2686894536018 Other DB loss: 20.159627354616532 Correct: 94.23076923076923%\n",
            "Epoch: 85 Training loss: 21.112069504742976 Eval loss: 1619.1497336626053 Other DB loss: 18.827099426067434 Correct: 92.3076923076923%\n",
            "Epoch: 86 Training loss: 18.550829544576118 Eval loss: 1573.3300079107285 Other DB loss: 16.369213057565503 Correct: 94.23076923076923%\n",
            "Epoch: 87 Training loss: 16.19270025813603 Eval loss: 1619.487826347351 Other DB loss: 16.982853229157627 Correct: 96.15384615384616%\n",
            "Epoch: 88 Training loss: 15.31647337769391 Eval loss: 1569.754334807396 Other DB loss: 18.230157893005526 Correct: 94.23076923076923%\n",
            "Epoch: 89 Training loss: 15.083130264130887 Eval loss: 1593.4717173576355 Other DB loss: 17.5417349596828 Correct: 92.3076923076923%\n",
            "Epoch: 90 Training loss: 18.547907441097777 Eval loss: 1606.9381983876228 Other DB loss: 17.104799940541852 Correct: 92.3076923076923%\n",
            "Epoch: 91 Training loss: 17.264271483425546 Eval loss: 1606.459145963192 Other DB loss: 17.744368331419537 Correct: 92.3076923076923%\n",
            "Epoch: 92 Training loss: 15.159623014042154 Eval loss: 1575.6394119262695 Other DB loss: 17.692144304310204 Correct: 94.23076923076923%\n",
            "Epoch: 93 Training loss: 14.247876275214367 Eval loss: 1565.0103256702423 Other DB loss: 17.316639278666116 Correct: 94.23076923076923%\n",
            "Epoch: 94 Training loss: 13.312400340619206 Eval loss: 1527.132966697216 Other DB loss: 16.539108804950956 Correct: 94.23076923076923%\n",
            "Epoch: 95 Training loss: 13.726636075763963 Eval loss: 1521.5146489739418 Other DB loss: 14.749193729134277 Correct: 94.23076923076923%\n",
            "Epoch: 96 Training loss: 12.488079259055667 Eval loss: 1557.695929646492 Other DB loss: 14.278263075917494 Correct: 94.23076923076923%\n",
            "Epoch: 97 Training loss: 13.39165345323272 Eval loss: 1485.6049373149872 Other DB loss: 14.804230832407484 Correct: 94.23076923076923%\n",
            "Epoch: 98 Training loss: 11.410247650404926 Eval loss: 1485.766852259636 Other DB loss: 14.36676579498453 Correct: 94.23076923076923%\n",
            "Epoch: 99 Training loss: 10.917064519049745 Eval loss: 1513.01136636734 Other DB loss: 12.638045384199359 Correct: 94.23076923076923%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t7n4tDiZsvAs",
        "colab_type": "text"
      },
      "source": [
        "## Detecting empty image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nSTdUp1O1bak",
        "colab_type": "code",
        "outputId": "ca9600f2-057b-43a3-8176-57cd8d51d49c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "empty_image = io.imread('/content/Lithuanian_OCR/Data/white.jpg')\n",
        "empty_image = rgb2gray(empty_image)\n",
        "output = network(torch.Tensor(empty_image).cuda().flatten().float())\n",
        "print(output)\n",
        "print(get_max_from_tensor(output))\n",
        "print(output[get_max_from_tensor(output) - 1])\n",
        "\n",
        "prob_treshold = output[get_max_from_tensor(output) - 1].item()\n",
        "print(prob_treshold)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([-13.3847, -13.3939, -13.4682], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1\n",
            "tensor(-13.3847, device='cuda:0', grad_fn=<SelectBackward>)\n",
            "-13.384712219238281\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qYul-0J0szAt",
        "colab_type": "text"
      },
      "source": [
        "## Detecting images from other datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uG-7pkvtsQC_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "prob_sum = 0\n",
        "\n",
        "detected_probs = []\n",
        "\n",
        "for data in other_val_loader:\n",
        "  images = data['image']\n",
        "  labels = torch.from_numpy(np.array(name_to_int(data['class_name'])))\n",
        "\n",
        "  for i in range(len(images)):\n",
        "    output = network(images[i].cuda().flatten().float())\n",
        "    prob = output[get_max_from_tensor(output) - 1].item()\n",
        "    prob_sum += prob\n",
        "    detected_probs.append(prob)\n",
        "\n",
        "prob_average = prob_sum/len(other_val_dataset)\n",
        "\n",
        "if prob_average > prob_treshold:\n",
        "  prob_treshold = prob_average"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mLlwCfdpyZcg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "f002b197-31a5-4d68-8f6e-708d3517a7fa"
      },
      "source": [
        "counter = 0\n",
        "\n",
        "for i in detected_probs:\n",
        "  if(i > prob_treshold):\n",
        "    counter += 1\n",
        "    print(\"False {}\".format(i))\n",
        "\n",
        "print()\n",
        "print(\"Treshold: {}\".format(prob_treshold))\n",
        "print(\"Accuracy: {}%\".format(100*(len(detected_probs)-counter)/len(detected_probs)))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "False -7.31141471862793\n",
            "False -2.627504587173462\n",
            "False 2.1341350078582764\n",
            "False -7.6790361404418945\n",
            "False -2.363929271697998\n",
            "\n",
            "Treshold: -7.8626912169986305\n",
            "Accuracy: 86.11111111111111%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rTDMpC0VycZS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "prob_treshold += 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CfDeUsDHs2Ge",
        "colab_type": "text"
      },
      "source": [
        "## Detecting images from current dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aDc8f2aEZ1-c",
        "colab_type": "code",
        "outputId": "6b76868f-8602-4e9a-dcff-3dd75dfc27f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        }
      },
      "source": [
        "lowest_prob = 100\n",
        "\n",
        "for data in test_loader:\n",
        "  images = data['image']\n",
        "  labels = torch.from_numpy(np.array(name_to_int(data['class_name'])))\n",
        "\n",
        "  for i in range(len(images)):\n",
        "    output = network(images[i].cuda().flatten().float())\n",
        "    \n",
        "    prob = output[get_max_from_tensor(output) - 1]\n",
        "    if prob < lowest_prob:\n",
        "      lowest_prob = prob\n",
        "\n",
        "    if(get_max_from_tensor(output) == labels[i] and prob > prob_treshold):\n",
        "      print(\"OK: {} == {} Probability: {}\".format(get_max_from_tensor(output), labels[i], prob))\n",
        "    elif(prob < prob_treshold):\n",
        "      print(\"False: Detected empty image on {} with probability: {}\".format(labels[i], prob))\n",
        "    else:\n",
        "      print(\"False: {} == {} Probability: {}\".format(get_max_from_tensor(output), labels[i], prob))\n",
        "\n",
        "print(\"Lowest Probability: {}\".format(lowest_prob))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "OK: 2 == 2 Probability: 12.367485046386719\n",
            "OK: 3 == 3 Probability: -1.2617096900939941\n",
            "OK: 3 == 3 Probability: -6.649481773376465\n",
            "OK: 2 == 2 Probability: 3.204002618789673\n",
            "OK: 3 == 3 Probability: 1.1665053367614746\n",
            "OK: 1 == 1 Probability: -5.09421443939209\n",
            "OK: 2 == 2 Probability: 10.621923446655273\n",
            "OK: 3 == 3 Probability: -1.6232125759124756\n",
            "OK: 3 == 3 Probability: 10.662201881408691\n",
            "OK: 3 == 3 Probability: 8.646599769592285\n",
            "OK: 2 == 2 Probability: 8.553979873657227\n",
            "OK: 1 == 1 Probability: 4.5402679443359375\n",
            "OK: 2 == 2 Probability: 6.985161781311035\n",
            "OK: 1 == 1 Probability: 6.254090785980225\n",
            "OK: 1 == 1 Probability: 10.039584159851074\n",
            "OK: 1 == 1 Probability: 5.480373382568359\n",
            "OK: 2 == 2 Probability: -3.62186861038208\n",
            "OK: 1 == 1 Probability: 3.683255910873413\n",
            "OK: 2 == 2 Probability: 8.045376777648926\n",
            "OK: 1 == 1 Probability: 3.31231427192688\n",
            "OK: 3 == 3 Probability: -5.8235063552856445\n",
            "OK: 2 == 2 Probability: -2.707728862762451\n",
            "OK: 2 == 2 Probability: 13.998620986938477\n",
            "Lowest Probability: -6.649481773376465\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}