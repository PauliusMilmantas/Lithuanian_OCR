{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "OCR.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "tqV3oHrg8mY-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import print_function, division\n",
        "import os\n",
        "import torch\n",
        "from skimage import io, transform\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, utils\n",
        "from skimage import io\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from skimage.color import rgb2gray\n",
        "\n",
        "import PIL\n",
        "from PIL import Image\n",
        "\n",
        "from google.colab import output\n",
        "import torchvision.models as models"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qZPVvFlrIHMt",
        "colab_type": "code",
        "outputId": "9c40bcb4-3df3-47a6-d8d0-958848cb89b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "%cd /content/\n",
        "if(os.path.isdir('/content/Lithuanian_OCR') == False):\n",
        "  !git clone https://github.com/PauliusMilmantas/Lithuanian_OCR"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NTdpat3XQh-5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def read_img(file_name):\n",
        "    img = io.imread(file_name)\n",
        "    img = [resize(img, (224, 224))]\n",
        "    img = torch.tensor(img)\n",
        "    img = img.permute(0, 3, 1, 2)\n",
        "    return img.float()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4dizldPQRNUj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ORCDataset(Dataset):\n",
        "  def __init__(self, root):\n",
        "    self.root = root\n",
        "\n",
        "  def __len__(self):\n",
        "    lt = 0\n",
        "    classes = os.listdir(self.root)\n",
        "    for cl in classes:\n",
        "      lt += len(os.listdir(self.root + '/' + cl))\n",
        "\n",
        "    return lt\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    if torch.is_tensor(idx):\n",
        "     idx = idx.tolist()\n",
        "\n",
        "    if(idx <= len(self)):\n",
        "      found_file = \"\"\n",
        "      found_type = \"\"\n",
        "\n",
        "      fldrs = os.listdir(self.root)\n",
        "      for fld in fldrs:\n",
        "        fls = os.listdir(self.root + '/' + fld + '/')\n",
        "        for fl in fls:\n",
        "          if(fl == str(idx) + \".jpg\"):\n",
        "            found_file = self.root + '/' + fld + '/' + fl         \n",
        "            found_type = fld\n",
        "\n",
        "      try:\n",
        "        img = read_img(found_file)\n",
        "        # img = rgb2gray(img)\n",
        "\n",
        "        return {'image': img, 'class_name': found_type}\n",
        "      except:\n",
        "        if(found_file != \"\"):\n",
        "          print(\"Bad file: \" + found_file)\n",
        "        else:\n",
        "          print(\"File not found, idx = \" + str(idx))\n",
        "    else:\n",
        "      print()\n",
        "      raise Exception(\"Dataset index out of boundaries\")\n",
        "\n",
        "train_dataset = ORCDataset('/content/Lithuanian_OCR/Data/training')\n",
        "val_dataset = ORCDataset('/content/Lithuanian_OCR/Data/val')\n",
        "test_dataset = ORCDataset('/content/Lithuanian_OCR/Data/test')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KR2HO96n8pXN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self, input_size, hidden1_size, hidden2_size, num_classes):\n",
        "        super(Net, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, hidden1_size)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(hidden1_size, hidden2_size)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.fc3 = nn.Linear(hidden2_size, num_classes)  \n",
        "    \n",
        "    def forward(self, x):\n",
        "        out = self.fc1(x)\n",
        "        out = self.relu1(out)\n",
        "        out = self.fc2(out)\n",
        "        out = self.relu2(out)\n",
        "        out = self.fc3(out)\n",
        "        return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MwTzb7K0_OSi",
        "colab_type": "code",
        "outputId": "d4bdff07-7549-4cdb-d1a3-c385de5f8db3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 503
        }
      },
      "source": [
        "# network = Net(4096, 130, 28, 3)\n",
        "\n",
        "network = models.AlexNet()\n",
        "\n",
        "\n",
        "\n",
        "optimizer = torch.optim.SGD(network.parameters(), lr=0.0000001, momentum=0.6)\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "print(network)"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "AlexNet(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "    (4): ReLU(inplace=True)\n",
            "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (7): ReLU(inplace=True)\n",
            "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): ReLU(inplace=True)\n",
            "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
            "  (classifier): Sequential(\n",
            "    (0): Dropout(p=0.5, inplace=False)\n",
            "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Dropout(p=0.5, inplace=False)\n",
            "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KIOL9zLnKiEu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size = len(train_dataset),shuffle=True)\n",
        "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size = len(val_dataset), shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size = len(test_dataset), shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SAi_TQWW-04_",
        "colab_type": "code",
        "outputId": "c8719e83-6c85-44f7-90bd-db5bdc48e18d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "dataiter = iter(train_loader)\n",
        "itr = dataiter.next()\n",
        "\n",
        "label = itr['class_name']\n",
        "img = itr['image']\n",
        "print(\"Class name: {}\".format(label[0]))\n",
        "\n",
        "fig = plt.figure(figsize = (5,5)) \n",
        "ax = fig.add_subplot(111)\n",
        "ax.imshow(img[0])"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Bad file: /content/Lithuanian_OCR/Data/training/B/95.jpg\n",
            "Bad file: /content/Lithuanian_OCR/Data/training/C/11.jpg\n",
            "Bad file: /content/Lithuanian_OCR/Data/training/C/10.jpg\n",
            "Bad file: /content/Lithuanian_OCR/Data/training/B/96.jpg\n",
            "Bad file: /content/Lithuanian_OCR/Data/training/B/103.jpg\n",
            "Bad file: /content/Lithuanian_OCR/Data/training/C/13.jpg\n",
            "Bad file: /content/Lithuanian_OCR/Data/training/A/78.jpg\n",
            "Bad file: /content/Lithuanian_OCR/Data/training/A/69.jpg\n",
            "Bad file: /content/Lithuanian_OCR/Data/training/B/113.jpg\n",
            "Bad file: /content/Lithuanian_OCR/Data/training/A/45.jpg\n",
            "Bad file: /content/Lithuanian_OCR/Data/training/C/1.jpg\n",
            "Bad file: /content/Lithuanian_OCR/Data/training/A/37.jpg\n",
            "Bad file: /content/Lithuanian_OCR/Data/training/B/106.jpg\n",
            "Bad file: /content/Lithuanian_OCR/Data/training/B/102.jpg\n",
            "Bad file: /content/Lithuanian_OCR/Data/training/A/73.jpg\n",
            "Bad file: /content/Lithuanian_OCR/Data/training/A/36.jpg\n",
            "Bad file: /content/Lithuanian_OCR/Data/training/B/84.jpg\n",
            "Bad file: /content/Lithuanian_OCR/Data/training/C/5.jpg\n",
            "Bad file: /content/Lithuanian_OCR/Data/training/B/116.jpg\n",
            "Bad file: /content/Lithuanian_OCR/Data/training/A/46.jpg\n",
            "Bad file: /content/Lithuanian_OCR/Data/training/C/2.jpg\n",
            "Bad file: /content/Lithuanian_OCR/Data/training/A/58.jpg\n",
            "Bad file: /content/Lithuanian_OCR/Data/training/A/32.jpg\n",
            "Bad file: /content/Lithuanian_OCR/Data/training/A/35.jpg\n",
            "Bad file: /content/Lithuanian_OCR/Data/training/A/56.jpg\n",
            "Bad file: /content/Lithuanian_OCR/Data/training/A/38.jpg\n",
            "Bad file: /content/Lithuanian_OCR/Data/training/B/86.jpg\n",
            "Bad file: /content/Lithuanian_OCR/Data/training/B/98.jpg\n",
            "Bad file: /content/Lithuanian_OCR/Data/training/B/90.jpg\n",
            "Bad file: /content/Lithuanian_OCR/Data/training/B/110.jpg\n",
            "Bad file: /content/Lithuanian_OCR/Data/training/B/99.jpg\n",
            "Bad file: /content/Lithuanian_OCR/Data/training/A/63.jpg\n",
            "Bad file: /content/Lithuanian_OCR/Data/training/A/59.jpg\n",
            "Bad file: /content/Lithuanian_OCR/Data/training/C/14.jpg\n",
            "Bad file: /content/Lithuanian_OCR/Data/training/C/16.jpg\n",
            "Bad file: /content/Lithuanian_OCR/Data/training/B/104.jpg\n",
            "Bad file: /content/Lithuanian_OCR/Data/training/C/4.jpg\n",
            "Bad file: /content/Lithuanian_OCR/Data/training/B/107.jpg\n",
            "Bad file: /content/Lithuanian_OCR/Data/training/C/22.jpg\n",
            "Bad file: /content/Lithuanian_OCR/Data/training/C/20.jpg\n",
            "Bad file: /content/Lithuanian_OCR/Data/training/A/70.jpg\n",
            "Bad file: /content/Lithuanian_OCR/Data/training/A/42.jpg\n",
            "Bad file: /content/Lithuanian_OCR/Data/training/B/88.jpg\n",
            "Bad file: /content/Lithuanian_OCR/Data/training/A/60.jpg\n",
            "Bad file: /content/Lithuanian_OCR/Data/training/A/33.jpg\n",
            "Bad file: /content/Lithuanian_OCR/Data/training/B/94.jpg\n",
            "Bad file: /content/Lithuanian_OCR/Data/training/A/47.jpg\n",
            "Bad file: /content/Lithuanian_OCR/Data/training/A/30.jpg\n",
            "Bad file: /content/Lithuanian_OCR/Data/training/A/52.jpg\n",
            "Bad file: /content/Lithuanian_OCR/Data/training/B/114.jpg\n",
            "Bad file: /content/Lithuanian_OCR/Data/training/A/28.jpg\n",
            "Bad file: /content/Lithuanian_OCR/Data/training/A/76.jpg\n",
            "Bad file: /content/Lithuanian_OCR/Data/training/C/27.jpg\n",
            "Bad file: /content/Lithuanian_OCR/Data/training/C/21.jpg\n",
            "Bad file: /content/Lithuanian_OCR/Data/training/A/62.jpg\n",
            "Bad file: /content/Lithuanian_OCR/Data/training/A/71.jpg\n",
            "Bad file: /content/Lithuanian_OCR/Data/training/A/55.jpg\n",
            "Bad file: /content/Lithuanian_OCR/Data/training/A/65.jpg\n",
            "Bad file: /content/Lithuanian_OCR/Data/training/C/15.jpg\n",
            "Bad file: /content/Lithuanian_OCR/Data/training/A/57.jpg\n",
            "Bad file: /content/Lithuanian_OCR/Data/training/B/83.jpg\n",
            "Bad file: /content/Lithuanian_OCR/Data/training/B/108.jpg\n",
            "Bad file: /content/Lithuanian_OCR/Data/training/B/80.jpg\n",
            "Bad file: /content/Lithuanian_OCR/Data/training/C/26.jpg\n",
            "Bad file: /content/Lithuanian_OCR/Data/training/C/12.jpg\n",
            "Bad file: /content/Lithuanian_OCR/Data/training/C/23.jpg\n",
            "Bad file: /content/Lithuanian_OCR/Data/training/A/77.jpg\n",
            "Bad file: /content/Lithuanian_OCR/Data/training/B/93.jpg\n",
            "Bad file: /content/Lithuanian_OCR/Data/training/A/34.jpg\n",
            "Bad file: /content/Lithuanian_OCR/Data/training/B/111.jpg\n",
            "Bad file: /content/Lithuanian_OCR/Data/training/B/81.jpg\n",
            "Bad file: /content/Lithuanian_OCR/Data/training/B/85.jpg\n",
            "Bad file: /content/Lithuanian_OCR/Data/training/B/109.jpg\n",
            "Bad file: /content/Lithuanian_OCR/Data/training/A/43.jpg\n",
            "Bad file: /content/Lithuanian_OCR/Data/training/B/115.jpg\n",
            "Bad file: /content/Lithuanian_OCR/Data/training/B/91.jpg\n",
            "Bad file: /content/Lithuanian_OCR/Data/training/A/53.jpg\n",
            "Bad file: /content/Lithuanian_OCR/Data/training/B/87.jpg\n",
            "Bad file: /content/Lithuanian_OCR/Data/training/A/50.jpg\n",
            "Bad file: /content/Lithuanian_OCR/Data/training/C/9.jpg\n",
            "Bad file: /content/Lithuanian_OCR/Data/training/B/89.jpg\n",
            "Bad file: /content/Lithuanian_OCR/Data/training/A/79.jpg\n",
            "Bad file: /content/Lithuanian_OCR/Data/training/A/68.jpg\n",
            "Bad file: /content/Lithuanian_OCR/Data/training/A/61.jpg\n",
            "Bad file: /content/Lithuanian_OCR/Data/training/A/66.jpg\n",
            "Bad file: /content/Lithuanian_OCR/Data/training/A/44.jpg\n",
            "Bad file: /content/Lithuanian_OCR/Data/training/A/67.jpg\n",
            "Bad file: /content/Lithuanian_OCR/Data/training/B/105.jpg\n",
            "Bad file: /content/Lithuanian_OCR/Data/training/B/101.jpg\n",
            "Bad file: /content/Lithuanian_OCR/Data/training/B/82.jpg\n",
            "Bad file: /content/Lithuanian_OCR/Data/training/A/64.jpg\n",
            "Bad file: /content/Lithuanian_OCR/Data/training/C/6.jpg\n",
            "Bad file: /content/Lithuanian_OCR/Data/training/B/97.jpg\n",
            "Bad file: /content/Lithuanian_OCR/Data/training/A/39.jpg\n",
            "Bad file: /content/Lithuanian_OCR/Data/training/A/40.jpg\n",
            "Bad file: /content/Lithuanian_OCR/Data/training/B/112.jpg\n",
            "Bad file: /content/Lithuanian_OCR/Data/training/C/7.jpg\n",
            "Bad file: /content/Lithuanian_OCR/Data/training/C/17.jpg\n",
            "Bad file: /content/Lithuanian_OCR/Data/training/C/19.jpg\n",
            "Bad file: /content/Lithuanian_OCR/Data/training/A/74.jpg\n",
            "Bad file: /content/Lithuanian_OCR/Data/training/C/8.jpg\n",
            "Bad file: /content/Lithuanian_OCR/Data/training/A/75.jpg\n",
            "Bad file: /content/Lithuanian_OCR/Data/training/C/0.jpg\n",
            "Bad file: /content/Lithuanian_OCR/Data/training/C/25.jpg\n",
            "Bad file: /content/Lithuanian_OCR/Data/training/A/72.jpg\n",
            "Bad file: /content/Lithuanian_OCR/Data/training/A/29.jpg\n",
            "Bad file: /content/Lithuanian_OCR/Data/training/A/51.jpg\n",
            "Bad file: /content/Lithuanian_OCR/Data/training/A/31.jpg\n",
            "Bad file: /content/Lithuanian_OCR/Data/training/C/3.jpg\n",
            "Bad file: /content/Lithuanian_OCR/Data/training/A/41.jpg\n",
            "Bad file: /content/Lithuanian_OCR/Data/training/A/49.jpg\n",
            "Bad file: /content/Lithuanian_OCR/Data/training/B/92.jpg\n",
            "Bad file: /content/Lithuanian_OCR/Data/training/C/18.jpg\n",
            "Bad file: /content/Lithuanian_OCR/Data/training/A/48.jpg\n",
            "Bad file: /content/Lithuanian_OCR/Data/training/A/54.jpg\n",
            "Bad file: /content/Lithuanian_OCR/Data/training/B/100.jpg\n",
            "Bad file: /content/Lithuanian_OCR/Data/training/C/24.jpg\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-113-36e1e09cf8c8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdataiter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mitr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'class_name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'image'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    383\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefault_collate_err_msg_format\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: default_collate: batch must contain tensors, numpy arrays, numbers, dicts or lists; found <class 'NoneType'>"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LMbDr5k1BOPE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_losses = []\n",
        "train_counter = []\n",
        "test_losses = []\n",
        "test_counter = [i*len(train_loader.dataset) for i in range(10 + 1)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aCwc6dI0BfdU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir results"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WNsrIgqgbT15",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def name_to_int(data):\n",
        "\n",
        "  switcher = {\n",
        "      'a': 1,\n",
        "      'a2': 2,\n",
        "      'b': 3,\n",
        "      'c': 4,\n",
        "      'c2': 5,\n",
        "      'd': 6,\n",
        "      'e': 7,\n",
        "      'e2': 8,\n",
        "      'e3': 9,\n",
        "      'f': 10,\n",
        "      'g': 11,\n",
        "      'h': 12,\n",
        "      'i': 13,\n",
        "      'i2': 14,\n",
        "      'j': 15,\n",
        "      'k': 16,\n",
        "      'l': 17,\n",
        "      'm': 18,\n",
        "      'n': 19,\n",
        "      'y': 20,\n",
        "      'A': 1,\n",
        "      'B': 2,\n",
        "      'C': 3\n",
        "  }\n",
        "\n",
        "  new_data = []\n",
        "\n",
        "  for dt in data:\n",
        "    new_data.append(switcher.get(dt))\n",
        "\n",
        "  return new_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YGa3hBILPt1E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_max_from_tensor(data):\n",
        "  maxVal = data[0]\n",
        "  maxId = 0\n",
        "  for i in range(len(data)):\n",
        "    if(data[i] > maxVal):\n",
        "      maxVal = data[i]\n",
        "      maxId = i\n",
        "\n",
        "  return maxId + 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rE8MNszDBZ_e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(train_loader, val_loader, epoch_amount, save_checkpoint = 10):\n",
        "  network.eval()\n",
        "  train_loss_hist = []\n",
        "  val_loss_hist = []\n",
        "  checkpoint = save_checkpoint\n",
        "  for epoch in range(epoch_amount):\n",
        "    num_images_train = 0\n",
        "    num_images_val = 0\n",
        "\n",
        "    # TRAINING DATASET\n",
        "    correct = 0\n",
        "    for data in train_loader:\n",
        "      images = data['image']\n",
        "      labels = torch.from_numpy(np.array(name_to_int(data['class_name'])))\n",
        "\n",
        "      num_images_train = len(images)\n",
        "\n",
        "      lossSum = 0\n",
        "      for idx in range(len(images)):\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = network(images[idx].flatten().float())\n",
        "\n",
        "        maxIdx = get_max_from_tensor(outputs)\n",
        "        real_value = np.zeros(3)\n",
        "        real_value[labels[idx] - 1] = 1\n",
        "\n",
        "        loss = criterion(outputs, torch.Tensor(real_value)) \n",
        "        \n",
        "        loss.backward()\n",
        "\n",
        "        lossSum += loss.item()\n",
        "        train_loss_hist.append(lossSum)\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "    # VALIDATION\n",
        "    for data in val_loader:\n",
        "      images = data['image']\n",
        "      labels = torch.from_numpy(np.array(name_to_int(data['class_name'])))\n",
        "\n",
        "      num_images_val = len(images)\n",
        "\n",
        "      lossSum = 0\n",
        "      for idx in range(len(images)):\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = network(images[idx].flatten().float())\n",
        "\n",
        "        if(labels[idx] == get_max_from_tensor(outputs)):\n",
        "          correct += 1\n",
        "\n",
        "        maxIdx = get_max_from_tensor(outputs)\n",
        "        real_value = np.zeros(3)\n",
        "        real_value[labels[idx] - 1] = 1\n",
        "        loss = criterion(outputs, torch.Tensor(real_value)) \n",
        "\n",
        "        lossSum += loss.item()\n",
        "        val_loss_hist.append(lossSum)\n",
        "\n",
        "    print(\"Epoch: {} Training loss: {} Eval loss: {} Correct: {}%\".format(epoch,train_loss_hist[len(train_loss_hist) - 1],val_loss_hist[len(val_loss_hist) - 1],correct*100/num_images_train))\n",
        "\n",
        "    if(checkpoint == 0):\n",
        "      torch.save(network.state_dict(), '/content/results/model.pth')\n",
        "      torch.save(optimizer.state_dict(), '/content/results/optimizer.pth')\n",
        "\n",
        "      checkpoint = save_checkpoint\n",
        "    else:\n",
        "      checkpoint -= 1\n",
        "\n",
        "train(train_loader, val_loader, 200)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aDc8f2aEZ1-c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for data in test_loader:\n",
        "  images = data['image']\n",
        "  labels = torch.from_numpy(np.array(name_to_int(data['class_name'])))\n",
        "\n",
        "  for i in range(len(images)):\n",
        "    output = network(images[i].flatten().float())\n",
        "    \n",
        "    if(get_max_from_tensor(output) == labels[i]):\n",
        "      print(\"OK: {} == {}\".format(get_max_from_tensor(output), labels[i]))\n",
        "    else:\n",
        "      print(\"False: {} == {}\".format(get_max_from_tensor(output), labels[i]))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}