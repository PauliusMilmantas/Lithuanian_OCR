{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "OCR.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "tqV3oHrg8mY-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import print_function, division\n",
        "import os\n",
        "import torch\n",
        "from skimage import io, transform\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, utils\n",
        "from skimage import io\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from skimage.color import rgb2gray\n",
        "\n",
        "import PIL\n",
        "from PIL import Image\n",
        "\n",
        "from google.colab import output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qZPVvFlrIHMt",
        "colab_type": "code",
        "outputId": "1c247c14-4470-4fb1-ac34-3dffec6e8eb6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "%cd /content/\n",
        "if(os.path.isdir('/content/Lithuanian_OCR') == False):\n",
        "  !git clone https://github.com/PauliusMilmantas/Lithuanian_OCR"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4dizldPQRNUj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ORCDataset(Dataset):\n",
        "  def __init__(self, root):\n",
        "    self.root = root\n",
        "\n",
        "  def __len__(self):\n",
        "    lt = 0\n",
        "    classes = os.listdir(self.root)\n",
        "    for cl in classes:\n",
        "      lt += len(os.listdir(self.root + '/' + cl))\n",
        "\n",
        "    return lt\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    if torch.is_tensor(idx):\n",
        "     idx = idx.tolist()\n",
        "\n",
        "    if(idx <= len(self)):\n",
        "      found_file = \"\"\n",
        "      found_type = \"\"\n",
        "\n",
        "      fldrs = os.listdir(self.root)\n",
        "      for fld in fldrs:\n",
        "        fls = os.listdir(self.root + '/' + fld + '/')\n",
        "        for fl in fls:\n",
        "          if(fl == str(idx) + \".jpg\"):\n",
        "            found_file = self.root + '/' + fld + '/' + fl         \n",
        "            found_type = fld\n",
        "\n",
        "      try:\n",
        "        img = io.imread(found_file)\n",
        "        # img = rgb2gray(img)\n",
        "\n",
        "        return {'image': img, 'class_name': found_type}\n",
        "      except:\n",
        "        if(found_file != \"\"):\n",
        "          print(\"Bad file: \" + found_file)\n",
        "        else:\n",
        "          print(\"File not found, idx = \" + str(idx))\n",
        "    else:\n",
        "      print()\n",
        "      raise Exception(\"Dataset index out of boundaries\")\n",
        "\n",
        "train_dataset = ORCDataset('/content/Lithuanian_OCR/Data/training')\n",
        "val_dataset = ORCDataset('/content/Lithuanian_OCR/Data/val')\n",
        "test_dataset = ORCDataset('/content/Lithuanian_OCR/Data/test')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KR2HO96n8pXN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self, input_size, hidden1_size, hidden2_size, num_classes):\n",
        "        super(Net, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, hidden1_size)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(hidden1_size, hidden2_size)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.fc3 = nn.Linear(hidden2_size, num_classes)  \n",
        "    \n",
        "    def forward(self, x):\n",
        "        out = self.fc1(x)\n",
        "        out = self.relu1(out)\n",
        "        out = self.fc2(out)\n",
        "        out = self.relu2(out)\n",
        "        out = self.fc3(out)\n",
        "        return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MwTzb7K0_OSi",
        "colab_type": "code",
        "outputId": "40731bcf-cf1d-4892-e627-1bf1a2eff29f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        }
      },
      "source": [
        "network = Net(2352, 130, 28, 20)\n",
        "optimizer = torch.optim.SGD(network.parameters(), lr=0.00001, momentum=0.6)\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "print(network)"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Net(\n",
            "  (fc1): Linear(in_features=2352, out_features=130, bias=True)\n",
            "  (relu1): ReLU()\n",
            "  (fc2): Linear(in_features=130, out_features=28, bias=True)\n",
            "  (relu2): ReLU()\n",
            "  (fc3): Linear(in_features=28, out_features=20, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KIOL9zLnKiEu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size = len(train_dataset),shuffle=True)\n",
        "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size = len(val_dataset), shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size = len(test_dataset), shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SAi_TQWW-04_",
        "colab_type": "code",
        "outputId": "386ee001-e457-4a49-ba8f-6c15b0acbc86",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        }
      },
      "source": [
        "dataiter = iter(train_loader)\n",
        "itr = dataiter.next()\n",
        "\n",
        "label = itr['class_name']\n",
        "img = itr['image']\n",
        "print(\"Class name: {}\".format(label[0]))\n",
        "\n",
        "fig = plt.figure(figsize = (5,5)) \n",
        "ax = fig.add_subplot(111)\n",
        "ax.imshow(img[0])"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Class name: y\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fb8f7bb86a0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 360x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LMbDr5k1BOPE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epochs = 10\n",
        "\n",
        "train_losses = []\n",
        "train_counter = []\n",
        "test_losses = []\n",
        "test_counter = [i*len(train_loader.dataset) for i in range(10 + 1)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aCwc6dI0BfdU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "dbcca18d-d816-409c-f273-faf499b79ee5"
      },
      "source": [
        "!mkdir results"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘results’: File exists\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WNsrIgqgbT15",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def name_to_int(data):\n",
        "\n",
        "  switcher = {\n",
        "      'a': 1,\n",
        "      'a2': 2,\n",
        "      'b': 3,\n",
        "      'c': 4,\n",
        "      'c2': 5,\n",
        "      'd': 6,\n",
        "      'e': 7,\n",
        "      'e2': 8,\n",
        "      'e3': 9,\n",
        "      'f': 10,\n",
        "      'g': 11,\n",
        "      'h': 12,\n",
        "      'i': 13,\n",
        "      'i2': 14,\n",
        "      'j': 15,\n",
        "      'k': 16,\n",
        "      'l': 17,\n",
        "      'm': 18,\n",
        "      'n': 19,\n",
        "      'y': 20\n",
        "  }\n",
        "\n",
        "  new_data = []\n",
        "\n",
        "  for dt in data:\n",
        "    new_data.append(switcher.get(dt))\n",
        "\n",
        "  return new_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YGa3hBILPt1E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_max_from_tensor(data):\n",
        "  maxVal = data[0]\n",
        "  maxId = 0\n",
        "  for i in range(len(data)):\n",
        "    if(data[i] > maxVal):\n",
        "      maxVal = data[i]\n",
        "      maxId = i\n",
        "\n",
        "  return maxId + 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rE8MNszDBZ_e",
        "colab_type": "code",
        "outputId": "bb7b4c78-2246-4154-cf1e-bb331016b029",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        }
      },
      "source": [
        "def train(train_loader, val_loader, epoch_amount, save_checkpoint = 10):\n",
        "  network.eval()\n",
        "  train_loss_hist = []\n",
        "  val_loss_hist = []\n",
        "  checkpoint = save_checkpoint\n",
        "  for epoch in range(epoch_amount):\n",
        "    num_images_train = 0\n",
        "    num_images_val = 0\n",
        "\n",
        "    # TRAINING DATASET\n",
        "    correct = 0\n",
        "    for data in train_loader:\n",
        "      images = data['image']\n",
        "      labels = torch.from_numpy(np.array(name_to_int(data['class_name'])))\n",
        "\n",
        "      num_images_train = len(images)\n",
        "\n",
        "      lossSum = 0\n",
        "      for idx in range(len(images)):\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = network(images[idx].flatten().float())\n",
        "\n",
        "        maxIdx = get_max_from_tensor(outputs)\n",
        "        real_value = np.zeros(20)\n",
        "        real_value[labels[idx] - 1] = 1\n",
        "\n",
        "        if(labels[idx] == get_max_from_tensor(outputs)):\n",
        "          correct += 1\n",
        "\n",
        "        loss = criterion(outputs, torch.Tensor(real_value)) \n",
        "        \n",
        "        loss.backward()\n",
        "\n",
        "        lossSum += loss.item()\n",
        "        train_loss_hist.append(lossSum)\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "    # VALIDATION\n",
        "    for data in val_loader:\n",
        "      images = data['image']\n",
        "      labels = torch.from_numpy(np.array(name_to_int(data['class_name'])))\n",
        "\n",
        "      num_images_val = len(images)\n",
        "\n",
        "      lossSum = 0\n",
        "      for idx in range(len(images)):\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = network(images[idx].flatten().float())\n",
        "\n",
        "        maxIdx = get_max_from_tensor(outputs)\n",
        "        real_value = np.zeros(20)\n",
        "        real_value[labels[idx] - 1] = 1\n",
        "        loss = criterion(outputs, torch.Tensor(real_value)) \n",
        "\n",
        "        lossSum += loss.item()\n",
        "        val_loss_hist.append(lossSum)\n",
        "\n",
        "    print(\"Epoch: {} Training loss: {} Eval loss: {} Correct: {}%\".format(epoch,train_loss_hist[len(train_loss_hist) - 1],val_loss_hist[len(val_loss_hist) - 1],correct*100/num_images_train))\n",
        "\n",
        "    if(checkpoint == 0):\n",
        "      torch.save(network.state_dict(), '/content/results/model.pth')\n",
        "      torch.save(optimizer.state_dict(), '/content/results/optimizer.pth')\n",
        "\n",
        "      checkpoint = save_checkpoint\n",
        "    else:\n",
        "      checkpoint -= 1\n",
        "\n",
        "train(train_loader, val_loader, 20)"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0 Training loss: 15.40581577271223 Eval loss: 5.68202655762434 Correct: 7.509881422924901%\n",
            "Epoch: 1 Training loss: 15.401501629501581 Eval loss: 5.680432949215174 Correct: 7.509881422924901%\n",
            "Epoch: 2 Training loss: 15.397195529192686 Eval loss: 5.67884173989296 Correct: 7.509881422924901%\n",
            "Epoch: 3 Training loss: 15.392893634736538 Eval loss: 5.677250571548939 Correct: 7.509881422924901%\n",
            "Epoch: 4 Training loss: 15.388595771044493 Eval loss: 5.67566491663456 Correct: 7.509881422924901%\n",
            "Epoch: 5 Training loss: 15.384302116930485 Eval loss: 5.67407451570034 Correct: 7.509881422924901%\n",
            "Epoch: 6 Training loss: 15.380014307796955 Eval loss: 5.672494143247604 Correct: 7.509881422924901%\n",
            "Epoch: 7 Training loss: 15.375736240297556 Eval loss: 5.670912966132164 Correct: 7.509881422924901%\n",
            "Epoch: 8 Training loss: 15.371461611241102 Eval loss: 5.669336035847664 Correct: 7.509881422924901%\n",
            "Epoch: 9 Training loss: 15.367193095386028 Eval loss: 5.667752910405397 Correct: 7.509881422924901%\n",
            "Epoch: 10 Training loss: 15.362930163741112 Eval loss: 5.6661790125072 Correct: 7.509881422924901%\n",
            "Epoch: 11 Training loss: 15.35867166146636 Eval loss: 5.664610959589481 Correct: 7.509881422924901%\n",
            "Epoch: 12 Training loss: 15.354416619986296 Eval loss: 5.663032807409763 Correct: 7.509881422924901%\n",
            "Epoch: 13 Training loss: 15.350173220038414 Eval loss: 5.661463480442762 Correct: 7.509881422924901%\n",
            "Epoch: 14 Training loss: 15.345935504883528 Eval loss: 5.6599021553993225 Correct: 7.509881422924901%\n",
            "Epoch: 15 Training loss: 15.34170088544488 Eval loss: 5.658334080129862 Correct: 7.509881422924901%\n",
            "Epoch: 16 Training loss: 15.337475329637527 Eval loss: 5.656771957874298 Correct: 7.509881422924901%\n",
            "Epoch: 17 Training loss: 15.333249360322952 Eval loss: 5.655214626342058 Correct: 7.509881422924901%\n",
            "Epoch: 18 Training loss: 15.329031124711037 Eval loss: 5.653650630265474 Correct: 7.509881422924901%\n",
            "Epoch: 19 Training loss: 15.324816077947617 Eval loss: 5.652092587202787 Correct: 7.509881422924901%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aDc8f2aEZ1-c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 503
        },
        "outputId": "c0bf12e7-8898-4aa4-c613-9dcc69c35138"
      },
      "source": [
        "for data in test_loader:\n",
        "  images = data['image']\n",
        "  labels = torch.from_numpy(np.array(name_to_int(data['class_name'])))\n",
        "\n",
        "  for i in range(len(images)):\n",
        "    output = network(images[i].flatten().float())\n",
        "    \n",
        "    if(get_max_from_tensor(output) == labels[i]):\n",
        "      print(\"OK: {} == {}\".format(get_max_from_tensor(output), labels[i]))\n",
        "    else:\n",
        "      print(\"False: {} == {}\".format(get_max_from_tensor(output), labels[i]))"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "False: 1 == 4\n",
            "False: 1 == 9\n",
            "False: 1 == 10\n",
            "False: 1 == 18\n",
            "False: 1 == 5\n",
            "False: 1 == 10\n",
            "False: 1 == 19\n",
            "False: 1 == 7\n",
            "False: 1 == 17\n",
            "False: 1 == 15\n",
            "False: 1 == 12\n",
            "OK: 1 == 1\n",
            "False: 1 == 3\n",
            "OK: 1 == 1\n",
            "False: 1 == 11\n",
            "False: 1 == 17\n",
            "False: 1 == 14\n",
            "False: 1 == 13\n",
            "False: 1 == 12\n",
            "False: 1 == 2\n",
            "False: 1 == 6\n",
            "False: 1 == 8\n",
            "False: 1 == 2\n",
            "False: 1 == 20\n",
            "False: 1 == 16\n",
            "False: 1 == 13\n",
            "False: 1 == 15\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}