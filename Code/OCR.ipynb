{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "OCR.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "tqV3oHrg8mY-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import print_function, division\n",
        "import os\n",
        "import torch\n",
        "from skimage import io, transform\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, utils\n",
        "from skimage import io\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from skimage.color import rgb2gray\n",
        "\n",
        "import PIL\n",
        "from PIL import Image\n",
        "\n",
        "from google.colab import output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qZPVvFlrIHMt",
        "colab_type": "code",
        "outputId": "5dc7cea9-577a-4802-d1eb-d050355d5421",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "%cd /content/\n",
        "if(os.path.isdir('/content/Lithuanian_OCR') == False):\n",
        "  !git clone https://github.com/PauliusMilmantas/Lithuanian_OCR"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "Cloning into 'Lithuanian_OCR'...\n",
            "remote: Enumerating objects: 1777, done.\u001b[K\n",
            "remote: Counting objects: 100% (1777/1777), done.\u001b[K\n",
            "remote: Compressing objects: 100% (1217/1217), done.\u001b[K\n",
            "remote: Total 1777 (delta 563), reused 1703 (delta 490), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (1777/1777), 18.65 MiB | 23.01 MiB/s, done.\n",
            "Resolving deltas: 100% (563/563), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4dizldPQRNUj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ORCDataset(Dataset):\n",
        "  def __init__(self, root):\n",
        "    self.root = root\n",
        "\n",
        "  def __len__(self):\n",
        "    lt = 0\n",
        "    classes = os.listdir(self.root)\n",
        "    for cl in classes:\n",
        "      lt += len(os.listdir(self.root + '/' + cl))\n",
        "\n",
        "    return lt\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    if torch.is_tensor(idx):\n",
        "     idx = idx.tolist()\n",
        "\n",
        "    if(idx <= len(self)):\n",
        "      found_file = \"\"\n",
        "      found_type = \"\"\n",
        "\n",
        "      fldrs = os.listdir(self.root)\n",
        "      for fld in fldrs:\n",
        "        fls = os.listdir(self.root + '/' + fld + '/')\n",
        "        for fl in fls:\n",
        "          if(fl == str(idx) + \".jpg\"):\n",
        "            found_file = self.root + '/' + fld + '/' + fl         \n",
        "            found_type = fld\n",
        "\n",
        "      try:\n",
        "        img = io.imread(found_file)\n",
        "        img = rgb2gray(img)\n",
        "\n",
        "        return {'image': img, 'class_name': found_type}\n",
        "      except:\n",
        "        if(found_file != \"\"):\n",
        "          print(\"Bad file: \" + found_file)\n",
        "        else:\n",
        "          print(\"File not found, idx = \" + str(idx))\n",
        "    else:\n",
        "      print()\n",
        "      raise Exception(\"Dataset index out of boundaries\")\n",
        "\n",
        "train_dataset = ORCDataset('/content/Lithuanian_OCR/Data/training')\n",
        "val_dataset = ORCDataset('/content/Lithuanian_OCR/Data/val')\n",
        "test_dataset = ORCDataset('/content/Lithuanian_OCR/Data/test')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KR2HO96n8pXN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self, input_size, hidden1_size, hidden2_size, num_classes):\n",
        "        super(Net, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, hidden1_size)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(hidden1_size, hidden2_size)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.fc3 = nn.Linear(hidden2_size, num_classes)  \n",
        "    \n",
        "    def forward(self, x):\n",
        "        out = self.fc1(x)\n",
        "        out = self.relu1(out)\n",
        "        out = self.fc2(out)\n",
        "        out = self.relu2(out)\n",
        "        out = self.fc3(out)\n",
        "        return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MwTzb7K0_OSi",
        "colab_type": "code",
        "outputId": "d8d26ea2-89cf-4b6d-9c19-3d9dbbaa3a0c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "network = Net(4096, 130, 28, 3)\n",
        "optimizer = torch.optim.SGD(network.parameters(), lr=0.0000001, momentum=0.6)\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "print(network)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Net(\n",
            "  (fc1): Linear(in_features=4096, out_features=130, bias=True)\n",
            "  (relu1): ReLU()\n",
            "  (fc2): Linear(in_features=130, out_features=28, bias=True)\n",
            "  (relu2): ReLU()\n",
            "  (fc3): Linear(in_features=28, out_features=3, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KIOL9zLnKiEu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size = len(train_dataset),shuffle=True)\n",
        "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size = len(val_dataset), shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size = len(test_dataset), shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SAi_TQWW-04_",
        "colab_type": "code",
        "outputId": "80bd022e-4261-4c67-b807-8e121af98f55",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "dataiter = iter(train_loader)\n",
        "itr = dataiter.next()\n",
        "\n",
        "label = itr['class_name']\n",
        "img = itr['image']\n",
        "print(\"Class name: {}\".format(label[0]))\n",
        "\n",
        "fig = plt.figure(figsize = (5,5)) \n",
        "ax = fig.add_subplot(111)\n",
        "ax.imshow(img[0])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "File not found, idx = 282\n",
            "File not found, idx = 263\n",
            "File not found, idx = 285\n",
            "File not found, idx = 280\n",
            "File not found, idx = 236\n",
            "File not found, idx = 268\n",
            "File not found, idx = 284\n",
            "File not found, idx = 277\n",
            "File not found, idx = 253\n",
            "File not found, idx = 265\n",
            "File not found, idx = 237\n",
            "File not found, idx = 300\n",
            "File not found, idx = 257\n",
            "File not found, idx = 255\n",
            "File not found, idx = 269\n",
            "File not found, idx = 264\n",
            "File not found, idx = 267\n",
            "File not found, idx = 242\n",
            "File not found, idx = 286\n",
            "File not found, idx = 294\n",
            "File not found, idx = 299\n",
            "File not found, idx = 298\n",
            "File not found, idx = 290\n",
            "File not found, idx = 259\n",
            "File not found, idx = 281\n",
            "File not found, idx = 249\n",
            "File not found, idx = 296\n",
            "File not found, idx = 262\n",
            "File not found, idx = 256\n",
            "File not found, idx = 254\n",
            "File not found, idx = 297\n",
            "File not found, idx = 295\n",
            "File not found, idx = 270\n",
            "File not found, idx = 289\n",
            "File not found, idx = 288\n",
            "File not found, idx = 241\n",
            "File not found, idx = 271\n",
            "File not found, idx = 244\n",
            "File not found, idx = 272\n",
            "File not found, idx = 276\n",
            "File not found, idx = 283\n",
            "File not found, idx = 266\n",
            "File not found, idx = 246\n",
            "File not found, idx = 240\n",
            "File not found, idx = 291\n",
            "File not found, idx = 239\n",
            "File not found, idx = 279\n",
            "File not found, idx = 275\n",
            "File not found, idx = 273\n",
            "File not found, idx = 248\n",
            "File not found, idx = 274\n",
            "File not found, idx = 243\n",
            "File not found, idx = 252\n",
            "File not found, idx = 287\n",
            "File not found, idx = 292\n",
            "File not found, idx = 258\n",
            "File not found, idx = 251\n",
            "File not found, idx = 293\n",
            "File not found, idx = 260\n",
            "File not found, idx = 247\n",
            "File not found, idx = 238\n",
            "File not found, idx = 261\n",
            "File not found, idx = 250\n",
            "File not found, idx = 245\n",
            "File not found, idx = 278\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-36e1e09cf8c8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdataiter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mitr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'class_name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'image'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    383\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontainer_abcs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_fields'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# namedtuple\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0melem_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontainer_abcs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_fields'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# namedtuple\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0melem_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontainer_abcs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_fields'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# namedtuple\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0melem_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LMbDr5k1BOPE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_losses = []\n",
        "train_counter = []\n",
        "test_losses = []\n",
        "test_counter = [i*len(train_loader.dataset) for i in range(10 + 1)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aCwc6dI0BfdU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir results"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WNsrIgqgbT15",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def name_to_int(data):\n",
        "\n",
        "  switcher = {\n",
        "      'a': 1,\n",
        "      'a2': 2,\n",
        "      'b': 3,\n",
        "      'c': 4,\n",
        "      'c2': 5,\n",
        "      'd': 6,\n",
        "      'e': 7,\n",
        "      'e2': 8,\n",
        "      'e3': 9,\n",
        "      'f': 10,\n",
        "      'g': 11,\n",
        "      'h': 12,\n",
        "      'i': 13,\n",
        "      'i2': 14,\n",
        "      'j': 15,\n",
        "      'k': 16,\n",
        "      'l': 17,\n",
        "      'm': 18,\n",
        "      'n': 19,\n",
        "      'y': 20,\n",
        "      'A': 1,\n",
        "      'B': 2,\n",
        "      'C': 3\n",
        "  }\n",
        "\n",
        "  new_data = []\n",
        "\n",
        "  for dt in data:\n",
        "    new_data.append(switcher.get(dt))\n",
        "\n",
        "  return new_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YGa3hBILPt1E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_max_from_tensor(data):\n",
        "  maxVal = data[0]\n",
        "  maxId = 0\n",
        "  for i in range(len(data)):\n",
        "    if(data[i] > maxVal):\n",
        "      maxVal = data[i]\n",
        "      maxId = i\n",
        "\n",
        "  return maxId + 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rE8MNszDBZ_e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(train_loader, val_loader, epoch_amount, save_checkpoint = 10):\n",
        "  network.eval()\n",
        "  train_loss_hist = []\n",
        "  val_loss_hist = []\n",
        "  checkpoint = save_checkpoint\n",
        "  for epoch in range(epoch_amount):\n",
        "    num_images_train = 0\n",
        "    num_images_val = 0\n",
        "\n",
        "    # TRAINING DATASET\n",
        "    correct = 0\n",
        "    for data in train_loader:\n",
        "      images = data['image']\n",
        "      labels = torch.from_numpy(np.array(name_to_int(data['class_name'])))\n",
        "\n",
        "      num_images_train = len(images)\n",
        "\n",
        "      lossSum = 0\n",
        "      for idx in range(len(images)):\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = network(images[idx].flatten().float())\n",
        "\n",
        "        maxIdx = get_max_from_tensor(outputs)\n",
        "        real_value = np.zeros(3)\n",
        "        real_value[labels[idx] - 1] = 1\n",
        "\n",
        "        loss = criterion(outputs, torch.Tensor(real_value)) \n",
        "        \n",
        "        loss.backward()\n",
        "\n",
        "        lossSum += loss.item()\n",
        "        train_loss_hist.append(lossSum)\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "    # VALIDATION\n",
        "    for data in val_loader:\n",
        "      images = data['image']\n",
        "      labels = torch.from_numpy(np.array(name_to_int(data['class_name'])))\n",
        "\n",
        "      num_images_val = len(images)\n",
        "\n",
        "      lossSum = 0\n",
        "      for idx in range(len(images)):\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = network(images[idx].flatten().float())\n",
        "\n",
        "        if(labels[idx] == get_max_from_tensor(outputs)):\n",
        "          correct += 1\n",
        "\n",
        "        maxIdx = get_max_from_tensor(outputs)\n",
        "        real_value = np.zeros(3)\n",
        "        real_value[labels[idx] - 1] = 1\n",
        "        loss = criterion(outputs, torch.Tensor(real_value)) \n",
        "\n",
        "        lossSum += loss.item()\n",
        "        val_loss_hist.append(lossSum)\n",
        "\n",
        "    print(\"Epoch: {} Training loss: {} Eval loss: {} Correct: {}%\".format(epoch,train_loss_hist[len(train_loss_hist) - 1],val_loss_hist[len(val_loss_hist) - 1],correct*100/num_images_train))\n",
        "\n",
        "    if(checkpoint == 0):\n",
        "      torch.save(network.state_dict(), '/content/results/model.pth')\n",
        "      torch.save(optimizer.state_dict(), '/content/results/optimizer.pth')\n",
        "\n",
        "      checkpoint = save_checkpoint\n",
        "    else:\n",
        "      checkpoint -= 1\n",
        "\n",
        "train(train_loader, val_loader, 200)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aDc8f2aEZ1-c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for data in test_loader:\n",
        "  images = data['image']\n",
        "  labels = torch.from_numpy(np.array(name_to_int(data['class_name'])))\n",
        "\n",
        "  for i in range(len(images)):\n",
        "    output = network(images[i].flatten().float())\n",
        "    \n",
        "    if(get_max_from_tensor(output) == labels[i]):\n",
        "      print(\"OK: {} == {}\".format(get_max_from_tensor(output), labels[i]))\n",
        "    else:\n",
        "      print(\"False: {} == {}\".format(get_max_from_tensor(output), labels[i]))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}